server:
  port: 8082

spring:

  application:
    name: job-executor-service

  autoconfigure:
    exclude:
      - org.springframework.boot.autoconfigure.jobrunr.JobRunrAutoConfiguration

  datasource:
    url: jdbc:postgresql://localhost:5432/job_demo_database
    username: postgres
    password: postgres


  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true

  kafka:
    bootstrap-servers: localhost:9092

    consumer:
      group-id: ${spring.application.name}-job-consumer  # customer-service-job-consumer
      auto-offset-reset: earliest
      enable-auto-commit: false
      fetch-min-size: 1024
      fetch-max-wait: 500

      properties:
        session.timeout.ms: 45000
        max.poll.interval.ms: 300000
        max.poll.records: 10
        heartbeat.interval.ms: 3000
        isolation.level: read_committed

        # Deserialización
        spring.json.trusted.packages: "*"
        spring.json.value.default.type: common.batch.dto.JobRequest
        spring.json.use.type.headers: false

        # Para el RecordInterceptor
        interceptor.classes: org.apache.kafka.clients.consumer.ConsumerInterceptor
        # Configuración de filtrado
        filter:
          enabled: true
          supported-domains: ${KAFKA_SUPPORTED_DOMAINS:ResumenDiarioClientesAsync}
          supported-job-types: ${KAFKA_SUPPORTED_JOB_TYPES:ASYNCRONOUS}

        # Configuración de interceptor
        interceptor:
          log-level: DEBUG
          enable-timing: true
          enable-headers-logging: false  # Por privacidad

    listener:
      ack-mode: manual_immediate
      concurrency: 3
      poll-timeout: 5000
      missing-topics-fatal: false

# Configuración específica de Kafka para este servicio
kafka:
  topics:
    job-requests: job-requests-topic
    job-results: job-results-topic
    dead-letter-queue: job-requests-dlq
    retry-topic: job-requests-retry
    retry-suffix: "-retry"
    dlq-suffix: "-dlq"
  interceptor:
    job-record-interceptor:
      enabled: true
      log-filtered-records: false
      metrics-enabled: true
  consumer:
    concurrency: 3
    poll-timeout: 5000

    # Filtrado por headers
    filter:
      enabled: true
      target-service: ${spring.application.name}  # Solo procesa jobs para este servicio
      supported-categories: "CUSTOMER,REPORTING"  # Categorías soportadas
      supported-domains: "SALES,OPERATIONS"       # Dominios soportados

    # Política de reintentos
    retry:
      max-attempts: 3
      backoff-delay: 1000
      max-delay: 10000

    # Dead Letter Queue
    dlq:
      enabled: true
      max-retries: 3

# Configuración del job
job:
  max-retries: 3
  retry-delay-ms: 5000

org:
  jobrunr:
    enabled: false

jobrunr:
  background-job-server:
    enabled: false

# Actuator y métricas
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
      base-path: /actuator
    enabled-by-default: true

  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
    metrics:
      enabled: true
    prometheus:
      enabled: true

  metrics:
    export:
      prometheus:
        enabled: true
        step: 30s  # Frecuencia de exportación
    enable:
      kafka: true
      jvm: true
      system: true
      logback: true
      processor: true

    tags:
      application: ${spring.application.name}
      environment: ${spring.profiles.active:local}
      region: local

    distribution:
      percentiles-histogram:
        http.server.requests: true
        kafka.consumer.fetch.manager.records.consumed: true
      sla:
        http.server.requests: 10ms, 50ms, 100ms, 200ms, 500ms, 1s, 5s


# Logging específico para Kafka
logging:
  level:
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    com.company.jobexecutor.kafka: DEBUG
